{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "307804a3-c02b-4a57-ac0d-172c30ddc851",
            "metadata": {},
            "source": [
                "# ChatGPT Retrieval Plugin Reader Demo\n",
                "\n",
                "Use our reader plugin to load data from ChatGPT"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "d48af8e1",
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "import logging\n",
                "import sys\n",
                "\n",
                "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
                "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "8ee4473a-094f-4d0a-a825-e1213db07240",
            "metadata": {},
            "source": [
                "#### Load documents"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0a2bcc07",
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "from llama_index.readers import ChatGPTRetrievalPluginReader\n",
                "import os"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "899522d1-3fd8-428d-be13-ca2c064c3a85",
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "bearer_token = os.getenv(\"BEARER_TOKEN\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "68cbd239-880e-41a3-98d8-dbb3fab55431",
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "# load documents\n",
                "reader = ChatGPTRetrievalPluginReader(\n",
                "    endpoint_url=\"http://localhost:8000\",\n",
                "    bearer_token=bearer_token\n",
                ")\n",
                "\n",
                "documents = reader.load_data(\"What did the author do growing up?\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "id": "ddd435b1-aba4-4847-bcf5-e0c61df50a9b",
            "metadata": {
                "tags": []
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "10"
                        ]
                    },
                    "execution_count": 12,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "len(documents)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "da9a6785-0bd9-44de-a0a2-4dd513b0730a",
            "metadata": {},
            "source": [
                "#### Build Index"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "id": "1270551f-0e4b-4429-a2bf-71146958f4c4",
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "from llama_index import GPTListIndex"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "id": "aa7443ef-77b1-4d71-b164-362e72a29064",
            "metadata": {
                "tags": []
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "INFO:llama_index.token_counter.token_counter:> [build_index_from_documents] Total LLM token usage: 0 tokens\n",
                        "> [build_index_from_documents] Total LLM token usage: 0 tokens\n",
                        "INFO:llama_index.token_counter.token_counter:> [build_index_from_documents] Total embedding token usage: 0 tokens\n",
                        "> [build_index_from_documents] Total embedding token usage: 0 tokens\n"
                    ]
                }
            ],
            "source": [
                "index = GPTListIndex(documents)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "04304299-fc3e-40a0-8600-f50c3292767e",
            "metadata": {},
            "source": [
                "#### Query Index"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "id": "eef29a5f-73e7-49ad-88c4-dd20a60ec91a",
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "from IPython.display import Markdown, display"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "id": "35369eda",
            "metadata": {
                "tags": []
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 2020 tokens\n",
                        "> [query] Total LLM token usage: 2020 tokens\n",
                        "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 0 tokens\n",
                        "> [query] Total embedding token usage: 0 tokens\n"
                    ]
                }
            ],
            "source": [
                "# set Logging to DEBUG for more detailed outputs\n",
                "query_engine = index.as_query_engine(response_mode=\"compact\")\n",
                "response = query_engine.query(\n",
                "    \"Summarize the retrieved content and describe what the author did growing up\",\n",
                ") "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "id": "bedbb693-725f-478f-be26-fa7180ea38b2",
            "metadata": {
                "tags": []
            },
            "outputs": [
                {
                    "data": {
                        "text/markdown": [
                            "<b>\n",
                            "The author grew up writing short stories and programming on an IBM 1401. After high school, they moved to England and worked on a program called Bel. They then started taking art classes at Harvard and RISD, and eventually dropped out to pursue painting. They moved to New York and started writing essays, which they published online. They also worked on spam filters and hosted dinner parties. In 2003, they had a big party at their house.</b>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "display(Markdown(f\"<b>{response}</b>\"))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "86c2a2d3-78e1-4468-9f93-2becae70e920",
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "llama_index",
            "language": "python",
            "name": "llama_index"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}