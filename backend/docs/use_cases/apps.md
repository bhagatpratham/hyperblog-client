# Integrations into LLM Applications

LlamaIndex modules provide plug and play data loaders, data structures, and query interfaces. They can be used in your downstream LLM Application. Some of these applications are described below.

### Chatbots

Chatbots are an incredibly popular use case for LLM's. LlamaIndex gives you the tools to build Knowledge-augmented chatbots and agents.

Relevant Resources:
- [Building a Chatbot](/guides/tutorials/building_a_chatbot.md)
- [Using with a LangChain Agent](/how_to/integrations/using_with_langchain.md)

### Full-Stack Web Application

LlamaIndex can be integrated into a downstream full-stack web application. It can be used in a backend server (such as Flask), packaged into a Docker container, and/or directly used in a framework such as Streamlit.

We provide tutorials and resources to help you get started in this area.

Relevant Resources:
- [Fullstack Application Guide](/guides/tutorials/fullstack_app_guide.md)
- [LlamaIndex Starter Pack](https://github.com/logan-markewich/llama_index_starter_pack)

