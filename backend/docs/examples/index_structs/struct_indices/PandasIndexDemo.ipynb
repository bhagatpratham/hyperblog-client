{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "e45f9b60-cd6b-4c15-958f-1feca5438128",
            "metadata": {},
            "source": [
                "# Pandas Index"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "119eb42b",
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "import logging\n",
                "import sys\n",
                "\n",
                "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
                "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "107396a9-4aa7-49b3-9f0f-a755726c19ba",
            "metadata": {
                "tags": []
            },
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/Users/jerryliu/Programming/llama_index/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
                        "  from .autonotebook import tqdm as notebook_tqdm\n"
                    ]
                }
            ],
            "source": [
                "from llama_index import SimpleDirectoryReader\n",
                "from IPython.display import Markdown, display"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "ec28d9b5-2d26-4522-9cfe-3ecc5ff40e59",
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "from llama_index.indices.struct_store import GPTPandasIndex\n",
                "import pandas as pd"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "5ece7d73-0f67-4ff5-95e5-249a25bd118c",
            "metadata": {},
            "source": [
                "### Let's start on a Toy DataFrame\n",
                "\n",
                "Very simple dataframe containing city and population pairs."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "1484fe58-4853-4a76-bffc-435a9cce3e2e",
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "# Test on some sample data \n",
                "df = pd.DataFrame(\n",
                "    {\n",
                "        \"city\": [\"Toronto\", \"Tokyo\", \"Berlin\"], \n",
                "        \"population\": [2930000, 13960000, 3645000]\n",
                "    }\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "4fea2edb-b3d4-4313-a656-d6edb00d93c0",
            "metadata": {
                "tags": []
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
                        "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
                        "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 0 tokens\n",
                        "> [build_index_from_nodes] Total embedding token usage: 0 tokens\n"
                    ]
                }
            ],
            "source": [
                "index = GPTPandasIndex(df=df)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "451836bc-b073-4838-8ab8-3def7d2c4d9d",
            "metadata": {
                "tags": []
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "> Pandas Instructions:\n",
                        "```\n",
                        "df['city'][df['population'].idxmax()]\n",
                        "```\n",
                        "> Pandas Output: Tokyo\n",
                        "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 180 tokens\n",
                        "> [query] Total LLM token usage: 180 tokens\n",
                        "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 0 tokens\n",
                        "> [query] Total embedding token usage: 0 tokens\n"
                    ]
                }
            ],
            "source": [
                "query_engine = index.as_query_engine(\n",
                "    verbose=True\n",
                ")\n",
                "response = query_engine.query(\n",
                "    \"What is the city with the highest population?\",\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "4253d4c3-f3e5-4779-bcd1-2e6e2818305f",
            "metadata": {
                "tags": []
            },
            "outputs": [
                {
                    "data": {
                        "text/markdown": [
                            "<b>Tokyo</b>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "display(Markdown(f\"<b>{response}</b>\"))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "5e10b7da-b355-49b2-9f80-f17541d4f850",
            "metadata": {
                "tags": []
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "df['city'][df['population'].idxmax()]\n"
                    ]
                }
            ],
            "source": [
                "# get pandas python instructions\n",
                "print(response.extra_info[\"pandas_instruction_str\"])"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "1de5eaf3-6129-47b1-b630-faf9138a04c5",
            "metadata": {},
            "source": [
                "### Analyzing the Titanic Dataset\n",
                "\n",
                "The Titanic dataset is one of the most popular tabular datasets in introductory machine learning\n",
                "Source: https://www.kaggle.com/c/titanic"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "id": "809f18c8-e38b-449e-b5ee-c2ea700f8698",
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "df = pd.read_csv(\"titanic_train.csv\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "id": "fb1758de-6310-4ed5-ae02-2dbf50d2c55f",
            "metadata": {
                "tags": []
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
                        "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
                        "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 0 tokens\n",
                        "> [build_index_from_nodes] Total embedding token usage: 0 tokens\n"
                    ]
                }
            ],
            "source": [
                "index = GPTPandasIndex(df=df)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "id": "f9dd658d-b62c-4e3b-aee9-0a06f57de032",
            "metadata": {
                "tags": []
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "> Pandas Instructions:\n",
                        "```\n",
                        "df['Survived'].corr(df['Age'])\n",
                        "```\n",
                        "> Pandas Output: -0.07722109457217755\n",
                        "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 829 tokens\n",
                        "> [query] Total LLM token usage: 829 tokens\n",
                        "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 0 tokens\n",
                        "> [query] Total embedding token usage: 0 tokens\n"
                    ]
                }
            ],
            "source": [
                "query_engine = index.as_query_engine(\n",
                "    verbose=True\n",
                ")\n",
                "response = query_engine.query(\n",
                "    \"What is the correlation between survival and age?\",\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "id": "60474389-341b-4187-87b2-83811546dcea",
            "metadata": {
                "tags": []
            },
            "outputs": [
                {
                    "data": {
                        "text/markdown": [
                            "<b>-0.07722109457217755</b>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "display(Markdown(f\"<b>{response}</b>\"))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "id": "af999a1f-fea6-4734-82e6-4450f1a06a3b",
            "metadata": {
                "tags": []
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "df['Survived'].corr(df['Age'])\n"
                    ]
                }
            ],
            "source": [
                "# get pandas python instructions\n",
                "print(response.extra_info[\"pandas_instruction_str\"])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "2f612c80-7261-4d97-9bc4-6b4772ecf735",
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "llama_index",
            "language": "python",
            "name": "llama_index"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
