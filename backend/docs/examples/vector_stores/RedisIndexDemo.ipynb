{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "0b692c73",
            "metadata": {},
            "source": [
                "# Redis Vector Store"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "1e7787c2",
            "metadata": {},
            "source": [
                "In this notebook we are going to show a quick demo of using the RedisVectorStore."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "id": "47264e32",
            "metadata": {
                "ExecuteTime": {
                    "end_time": "2023-02-10T12:20:23.988789Z",
                    "start_time": "2023-02-10T12:20:23.967877Z"
                }
            },
            "outputs": [],
            "source": [
                "import os\n",
                "import sys\n",
                "import logging\n",
                "import textwrap\n",
                "\n",
                "import warnings\n",
                "warnings.filterwarnings(\"ignore\")\n",
                "\n",
                "# stop huggingface warnings\n",
                "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
                "\n",
                "# Uncomment to see debug logs\n",
                "#logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
                "#logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
                "\n",
                "from llama_index import GPTVectorStoreIndex, SimpleDirectoryReader, Document\n",
                "from llama_index.vector_stores import RedisVectorStore\n",
                "from IPython.display import Markdown, display"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "3c692310",
            "metadata": {},
            "source": [
                "### Start Redis\n",
                "\n",
                "The easiest way to start Redis as a vector database is using the [redis-stack](https://hub.docker.com/r/redis/redis-stack) docker image.\n",
                "\n",
                "To follow every step of this tutorial, launch the image as follows:\n",
                "\n",
                "```bash\n",
                "docker run --name redis-vecdb -d -p 6379:6379 -p 8001:8001 redis/redis-stack:latest\n",
                "```\n",
                "\n",
                "This will also launch the RedisInsight UI on port 8001 which you can view at http://localhost:8001.\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "f9b97a89",
            "metadata": {},
            "source": [
                "### Setup OpenAI\n",
                "Lets first begin by adding the openai api key. This will allow us to access openai for embeddings and to use chatgpt."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "id": "0c9f4d21-145a-401e-95ff-ccb259e8ef84",
            "metadata": {
                "ExecuteTime": {
                    "end_time": "2023-02-10T12:20:24.908956Z",
                    "start_time": "2023-02-10T12:20:24.537064Z"
                },
                "pycharm": {
                    "is_executing": true
                }
            },
            "outputs": [],
            "source": [
                "import os\n",
                "os.environ[\"OPENAI_API_KEY\"] = \"sk-<your key here>\""
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "59ff935d",
            "metadata": {},
            "source": [
                "### Read in a dataset\n",
                "Here we will use a set of Paul Graham essays to provide the text to turn into embeddings, store in a ``RedisVectorStore`` and query to find context for our LLM QnA loop."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "68cbd239-880e-41a3-98d8-dbb3fab55431",
            "metadata": {
                "ExecuteTime": {
                    "end_time": "2023-02-10T12:20:30.175678Z",
                    "start_time": "2023-02-10T12:20:30.172456Z"
                },
                "pycharm": {
                    "is_executing": true
                }
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Document ID: 09206095-be73-4069-b9f6-ff76d1f03343 Document Hash: 77ae91ab542f3abb308c4d7c77c9bc4c9ad0ccd63144802b7cbe7e1bb3a4094e\n"
                    ]
                }
            ],
            "source": [
                "# load documents\n",
                "documents = SimpleDirectoryReader('../data/paul_graham').load_data()\n",
                "print('Document ID:', documents[0].doc_id, 'Document Hash:', documents[0].doc_hash)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "dd270925",
            "metadata": {},
            "source": [
                "### Initialize the Redis Vector Store\n",
                "\n",
                "Now we have our documents read in, we can initialize the Redis Vector Store. This will allow us to store our vectors in Redis and create an index.\n",
                "\n",
                "Here is the docstring for the RedisVectorStore:\n",
                "\n",
                "```python\n",
                "class RedisVectorStore(VectorStore):\n",
                "    \n",
                "    def __init__(\n",
                "        self,\n",
                "        index_name: Optional[str],\n",
                "        index_prefix: Optional[str] = \"gpt_index\",\n",
                "        index_args: Optional[Dict[str, Any]] = None,\n",
                "        redis_url: Optional[str] = \"redis://localhost:6379\",\n",
                "        overwrite: bool = False,\n",
                "        **kwargs: Any,\n",
                "    ) -> None:\n",
                "        \"\"\"Initialize RedisVectorStore.\n",
                "\n",
                "        Args:\n",
                "            index_name (str): Name of the index.\n",
                "            index_prefix (str): Prefix for the index. Defaults to \"gpt_index\".\n",
                "            index_args (Dict[str, Any]): Arguments for the index. Defaults to None.\n",
                "            redis_url (str): URL for the redis instance. Defaults to \"redis://localhost:6379\".\n",
                "            overwrite (bool): Whether to overwrite the index if it already exists. Defaults to False.\n",
                "            kwargs (Any): Additional arguments to pass to the redis client.\n",
                "\n",
                "        Raises:\n",
                "            ValueError: If redis-py is not installed\n",
                "            ValueError: If RediSearch is not installed\n",
                "\n",
                "        Examples:\n",
                "            >>> from gpt_index.vector_stores.redis import RedisVectorStore\n",
                "            >>> # Create a RedisVectorStore\n",
                "            >>> vector_store = RedisVectorStore(\n",
                "            >>>     index_name=\"my_index\",\n",
                "            >>>     index_prefix=\"gpt_index\",\n",
                "            >>>     index_args={\"algorithm\": \"HNSW\", \"m\": 16, \"efConstruction\": 200, \"distance_metric\": \"cosine\"},\n",
                "            >>>     redis_url=\"redis://localhost:6379/\",\n",
                "            >>>     overwrite=True)\n",
                "\n",
                "        \"\"\"\n",
                "```\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "ba1558b3",
            "metadata": {
                "ExecuteTime": {
                    "end_time": "2023-02-10T12:20:33.735897Z",
                    "start_time": "2023-02-10T12:20:30.404245Z"
                },
                "pycharm": {
                    "is_executing": true
                }
            },
            "outputs": [],
            "source": [
                "from llama_index.storage.storage_context import StorageContext\n",
                "\n",
                "\n",
                "vector_store = RedisVectorStore(\n",
                "    index_name=\"pg_essays\",\n",
                "    index_prefix=\"llama\",\n",
                "    redis_url=\"redis://localhost:6379\",\n",
                "    overwrite=True\n",
                ")\n",
                "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
                "index = GPTVectorStoreIndex.from_documents(documents, storage_context=storage_context)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "04304299-fc3e-40a0-8600-f50c3292767e",
            "metadata": {},
            "source": [
                "# Query the data\n",
                "Now that we have our document stored in the index, we can ask questions against the index. The index will use the data stored in itself as the knowledge base for chatgpt."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "35369eda",
            "metadata": {
                "ExecuteTime": {
                    "end_time": "2023-02-10T12:20:51.328762Z",
                    "start_time": "2023-02-10T12:20:33.822688Z"
                }
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        " The author learned that the AI programs of the time were not capable of understanding natural\n",
                        "language, and that the field of AI was a hoax. He also learned that he could make art, and that he\n",
                        "could pass the entrance exam for the Accademia di Belli Arti in Florence. He also learned Lisp\n",
                        "hacking and wrote his dissertation on applications of continuations.\n"
                    ]
                }
            ],
            "source": [
                "query_engine = index.as_query_engine()\n",
                "response = query_engine.query(\"What did the author learn?\")\n",
                "print(textwrap.fill(str(response), 100))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "id": "99212d33",
            "metadata": {
                "ExecuteTime": {
                    "end_time": "2023-02-10T12:21:10.337294Z",
                    "start_time": "2023-02-10T12:20:51.338718Z"
                }
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        " A hard moment for the author was when he realized that the AI programs of the time were a hoax and\n",
                        "that there was an unbridgeable gap between what they could do and actually understanding natural\n",
                        "language. He had invested a lot of time and energy into learning about AI and was disappointed to\n",
                        "find out that the field was not as promising as he had thought.\n"
                    ]
                }
            ],
            "source": [
                "response = query_engine.query(\"What was a hard moment for the author?\")\n",
                "print(textwrap.fill(str(response), 100))"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "4d7bc976",
            "metadata": {},
            "source": [
                "### Saving and Loading\n",
                "\n",
                "Redis allows the user to perform backups in the background or synchronously. With Llamaindex, the ``RedisVectorStore.persist()`` function can be used to trigger such a backup."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "id": "09836567",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "redis  redisinsight\n"
                    ]
                }
            ],
            "source": [
                "!docker exec -it redis-vecdb ls /data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "id": "93ef500b",
            "metadata": {},
            "outputs": [],
            "source": [
                "vector_store.persist(persist_path=\"\") # persist_path means nothing for RedisVectorStore"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "id": "ed5ab256",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "dump.rdb  redis  redisinsight\n"
                    ]
                }
            ],
            "source": [
                "!docker exec -it redis-vecdb ls /data"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "52b975a7",
            "metadata": {},
            "source": [
                "### Deleting documents or index completely\n",
                "\n",
                "Sometimes it may be useful to delete documents or the entire index. This can be done using the `delete` and `delete_index` methods."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "id": "6fe322f7",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "'09206095-be73-4069-b9f6-ff76d1f03343'"
                        ]
                    },
                    "execution_count": 16,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "document_id = documents[0].doc_id\n",
                "document_id"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "id": "ae4fb2b0",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Number of documents 24\n"
                    ]
                }
            ],
            "source": [
                "redis_client = vector_store.client\n",
                "print(\"Number of documents\", len(redis_client.keys()))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "id": "0ce45788",
            "metadata": {},
            "outputs": [],
            "source": [
                "vector_store.delete(document_id)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "id": "4a1ac683",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Number of documents 14\n"
                    ]
                }
            ],
            "source": [
                "print(\"Number of documents\", len(redis_client.keys()))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "id": "c380605a",
            "metadata": {},
            "outputs": [],
            "source": [
                "# now lets delete the index entirely (happens in the background, may take a second)\n",
                "# this will delete all the documents and the index\n",
                "vector_store.delete_index()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "id": "474ad4ee",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Number of documents 0\n"
                    ]
                }
            ],
            "source": [
                "print(\"Number of documents\", len(redis_client.keys()))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.13"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
