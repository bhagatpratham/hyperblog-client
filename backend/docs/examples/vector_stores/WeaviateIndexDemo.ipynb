{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "307804a3-c02b-4a57-ac0d-172c30ddc851",
            "metadata": {},
            "source": [
                "# Weaviate Vector Store"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "f7010b1d-d1bb-4f08-9309-a328bb4ea396",
            "metadata": {},
            "source": [
                "#### Creating a Weaviate Client"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "eccceb71",
            "metadata": {},
            "outputs": [],
            "source": [
                "import logging\n",
                "import sys\n",
                "\n",
                "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
                "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "72a4b618-668d-4713-84c5-6362030e9f19",
            "metadata": {},
            "outputs": [],
            "source": [
                "import weaviate"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "df8b27e5-5ad5-4dfe-90c7-0cf1f1d1b37f",
            "metadata": {},
            "outputs": [],
            "source": [
                "# cloud\n",
                "# resource_owner_config = weaviate.AuthClientPassword(\n",
                "#   username = \"<username>\", \n",
                "#   password = \"<password>\", \n",
                "# )\n",
                "# client = weaviate.Client(\"https://<cluster-id>.semi.network/\", auth_client_secret=resource_owner_config)\n",
                "\n",
                "# local\n",
                "client = weaviate.Client('http://localhost:8080')"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "8ee4473a-094f-4d0a-a825-e1213db07240",
            "metadata": {},
            "source": [
                "#### Load documents, build the GPTVectorStoreIndex"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "0a2bcc07",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "INFO:numexpr.utils:Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
                        "Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
                        "INFO:numexpr.utils:NumExpr defaulting to 8 threads.\n",
                        "NumExpr defaulting to 8 threads.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/Users/suo/miniconda3/envs/llama/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
                        "  from .autonotebook import tqdm as notebook_tqdm\n"
                    ]
                }
            ],
            "source": [
                "from llama_index import GPTVectorStoreIndex, SimpleDirectoryReader\n",
                "from llama_index.vector_stores import WeaviateVectorStore\n",
                "from IPython.display import Markdown, display"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "68cbd239-880e-41a3-98d8-dbb3fab55431",
            "metadata": {},
            "outputs": [],
            "source": [
                "# load documents\n",
                "documents = SimpleDirectoryReader('../data/paul_graham').load_data()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "ba1558b3",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
                        "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
                        "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 20729 tokens\n",
                        "> [build_index_from_nodes] Total embedding token usage: 20729 tokens\n"
                    ]
                }
            ],
            "source": [
                "from llama_index.storage.storage_context import StorageContext\n",
                "\n",
                "\n",
                "vector_store = WeaviateVectorStore(weaviate_client=client)\n",
                "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
                "index = GPTVectorStoreIndex.from_documents(documents, storage_context=storage_context)\n",
                "\n",
                "# NOTE: you may also choose to define a class_prefix manually.\n",
                "# class_prefix = \"test_prefix\"\n",
                "# vector_store = WeaviateVectorStore(weaviate_client=client, class_prefix=class_prefix)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "04304299-fc3e-40a0-8600-f50c3292767e",
            "metadata": {},
            "source": [
                "#### Query Index"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "35369eda",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "INFO:llama_index.token_counter.token_counter:> [retrieve] Total LLM token usage: 0 tokens\n",
                        "> [retrieve] Total LLM token usage: 0 tokens\n",
                        "INFO:llama_index.token_counter.token_counter:> [retrieve] Total embedding token usage: 8 tokens\n",
                        "> [retrieve] Total embedding token usage: 8 tokens\n",
                        "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 1920 tokens\n",
                        "> [get_response] Total LLM token usage: 1920 tokens\n",
                        "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n",
                        "> [get_response] Total embedding token usage: 0 tokens\n"
                    ]
                }
            ],
            "source": [
                "# set Logging to DEBUG for more detailed outputs\n",
                "query_engine = index.as_query_engine()\n",
                "response = query_engine.query(\"What did the author do growing up?\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "bedbb693-725f-478f-be26-fa7180ea38b2",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/markdown": [
                            "<b>\n",
                            "Growing up, the author wrote short stories, programmed on an IBM 1401, and nagged his father to buy him a TRS-80 microcomputer. He wrote simple games, a program to predict how high his model rockets would fly, and a word processor. He also studied philosophy in college, but switched to AI after becoming bored with it. He then took art classes at Harvard and applied to art schools, eventually attending RISD.</b>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "display(Markdown(f\"<b>{response}</b>\"))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f2e0997c",
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "bc9a2ad0",
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.16"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
